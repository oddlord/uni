\chapter{Errori ed aritmetica finita}
	\label{chapterErroriAritmeticaFinita}
	\pagenumbering{arabic}
	\minitoc \mtcskip
	\lettrine{Q}{}uando si utilizza un metodo numerico per risolvere un problema matematico non sempre si ottiene un \textbf{risultato esatto}, ma un \textbf{risultato approssimato}, che differisce dal risultato esatto.\\
	Sia $x \in \mathbb{R}$ il risultato esatto e $\tilde{x}$ il risultato approssimato corrispondente \begin{defi}
		La quantità
		$$ \Delta x \equiv \tilde{x} - x $$
		rappresenta l'\textbf{errore assoluto} commesso.
	\end{defi}
	Tuttavia questa quantità non è un buon indice di valutazione dell'errore, in quanto l'errore non viene in alcun modo rapportato all'ordine di grandezza del risultato: un errore assoluto pari a $10^{-3}$ rappresenta un errore trascurabile se, ad esempio, $x = 10^{8}$ ma allo stesso tempo è un errore enorme per $x = 10^{-3}$.\\
	Per poter meglio valutare il ``peso'' che l'errore ha sul risultato approssimato viene quindi introdotto un nuovo concetto
	\begin{defi}
		Se $x \neq 0$, si dice \textbf{errore relativo} la quantità
		$$\varepsilon_x \equiv \dfrac{\Delta x}{x} = \dfrac{\tilde{x} - x}{x}$$
	\end{defi}
	Spesso l'errore relativo viene rapportato ad 1: valori di $\varepsilon_x$ vicini a 0 significano un errore ``piccolo'', mentre un errore relativo pari ad 1 implica una perdita totale di informazione.\\	
	Le cause che portano al verificarsi di tale errore sul risultato sono principalmente tre:
	\begin{itemize}
		\item errori di discretizzazione, o troncamento;
		\item errori di convergenza;
		\item errori di \textit{round-off}.
	\end{itemize}
	
	\section{Errori di discretizzazione}
		Si ha un errore di \textbf{discretizzazione}, o di \textbf{troncamento}, quando il problema dato viene formulato nel continuo e, per poter definire un metodo numerico che lo risolva eseguibile su calcolatore, è necessario sostituire tale problema con uno discreto che lo approssimi.
		
	\section{Errori di convergenza}
		\label{sez1.2}
		Se un metodo numerico utilizza una \textbf{funzione d'iterazione} $\Phi (x)$, allora si dice che il metodo è di tipo \textbf{iterativo}: esso non fornisce direttamente la soluzione al problema, ma genera una successione di risultati intermedi $\{x_n\}$, definita da
		\begin{equation}\label{iter}x_{n+1} = \Phi (x_n),\quad n=0, 1, 2, \dots,\end{equation}
		con $x_0$ \textit{approssimazione iniziale} fissata, che converge alla soluzione $x^*$, ovvero
		\begin{equation}\label{conv}\lim_{x \to +\infty} x_n = x^*.\end{equation}
		È ovvio però che un calcolatore non può eseguire infinite iterazioni, quindi sarà necessario definire un opportuno \textbf{criterio d'arresto}.
		\begin{defi}
			Se l'iterazione (\ref{iter}) viene arrestata a $n = N - 1$, utilizzando come risultato $x_N$ al posto di $x^*$, la quantità
			$$x_N - x^*$$
			viene detta \textbf{errore assoluto di convergenza}.
		\end{defi}
		
	\section{Errori di \textit{round-off}}
		Si ha un \textbf{errore di round-off}, e più precisamente \textbf{di rappresentazione}, quando si tenta di rappresentare una quantità numerica, che spesso ha bisogno di una quantità infinita di informazione per essere rappresentata esattamente (come ad esempio i numeri irrazionali), su un calcolatore, che per forza di cose è costretto ad utilizzare un'\textit{aritmetica finita}.\\
		Quindi qualunque numero, in un calcolatore, viene rappresentato mediante una quantità finita di informazione, dando luogo, appunto, agli \textit{errori di rappresentazione}.\\
		In un calcolatore, inoltre, ogni numero viene rappresentato utilizzando una \textit{notazione posizionale} che utilizza le potenza di una base fissata $b \in \mathbb{N}$, con $b \geq 2$.\\
		Quando si parla di \textit{errore di rappresentazione} si distinguono due casi:
		\begin{itemize}
			\item numeri interi;
			\item numeri reali.
		\end{itemize}
		
		\subsection{Numeri interi}
			Un numero intero viene rappresentato, con base $b \in \mathbb{N}$, mediante una stringa del tipo
			$$\alpha_0\alpha_1\dots\alpha_N,$$
			con
			$$\alpha_0 \in \{+, -\},\quad \alpha_i \in \{0,1,\dots,b-1\},\quad i=1,\dots,N.$$
			Questa stringa corrisponde al numero
			$$
				n =
				\begin{cases}
					\sum_{i=1}^{N}\alpha_ib^{N-i}, & \quad \text{se $\alpha_0=+$},\\
					\sum_{i=1}^{N}\alpha_ib^{N-i} - b^N, & \quad \text{se $\alpha_0=-$}.
				\end{cases}
			$$
			Quindi risulta che l'insieme dei numeri correttamente rappresentabili tramite questa rappresentazione è
			$$[-b^N, b^N -1].$$
			
		\subsection{Numeri reali}
			Fissata una base $b \in \mathbb{N}$, un numero reale viene rappresentato mediante una stringa del tipo
			\begin{equation}\label{stringaReale}\alpha_0\alpha_1\dots\alpha_m\beta_1\dots\beta_s,\end{equation}
			dove
			\begin{equation}\label{condStringaReale}\alpha_0 \in \{+,-\},\quad\alpha_i,\beta_j\in\{0,1,\dots,b-1\},\quad i=1,\dots,m,\quad j=1,\dots,s,\end{equation}
			e tale che
			$$\alpha_1 \neq 0,$$
			cioè tale che il numero sia normalizzato. Questa rappresentazione viene detta \textbf{rappresentazione scientifica normalizzata} in base \textit{b}.\\
			Fissato lo \textbf{shift} $\nu\in\mathbb{N}$, la stringa (\ref{stringaReale}) rappresenta il numero
			\begin{equation}
				\label{numReale}
				r = 
				\begin{cases}
					\rho b^{\eta} & \quad \text{se $\alpha_0 = +$,}\\
					-\rho b^{\eta} & \quad \text{se $\alpha_0 = -$.}
				\end{cases}
			\end{equation}
			dove $\rho$ e $\eta$, rispettivamente \textbf{mantissa} ed \textbf{esponente}, sono le quantità
			$$\rho=\pm\sum_{i=1}^{m}\alpha_ib^{1-i},\qquad \eta=\left(\sum_{j=1}^{s}\beta_jb^{s-j}\right) -\nu.$$
			Talvolta viene chiamato esponente anche la sola quantità $e=\sum_{j=1}^{s}\beta_jb^{s-j}$, ovvero la quantità tale che $\eta=e-\nu$.
			\begin{defi}
				L'\textbf{insieme dei numeri di macchina}, o numeri \textit{floating-point}, è definito come
				$$\mathcal{M}=\{0\}\cup\{\text{numeri della forma (\ref{stringaReale})}\}.$$
			\end{defi}
			\begin{teo}
				\label{teor1.1}
				$\mathcal{M}$ ha un numero finito di elementi.
			\end{teo}
			\begin{teo}
				Per ogni numero reale della forma (\ref{numReale}) vale
				$$1\leq |\rho| < b.$$
			\end{teo}
			\begin{teo}
				\label{teor1.3}
				Il più piccolo ed il più grande (in valore assoluto), tra i numeri di macchina diversi da 0, sono rispettivamente dati da:
				\begin{align}
					\label{rMinMax}
					&r_{min}=b^{-\nu},\\
					&r_{max}=(1-b^{-m})b^{\varphi},\quad \varphi=b^s-\nu.
				\end{align}
			\end{teo}
			Solitamente lo \textit{shift} $\nu$ viene scelto in modo che $r_{min} \approx r_{max}^{-1}$, ovvero $\nu\approx\sfrac{b^s}{2}$.\\
			Risulta allora che i numeri di macchina appartengono all'insieme
			\begin{equation}\label{insI}\mathcal{I}=[-r_{max}, -r_{min}]\cup\{0\}\cup[r_{min}, r_{max}],\end{equation}
			che ha un numero infinito di elementi, mentre, per il Teorema \ref{teor1.1}, $\mathcal{M}$ ha un numero finito di elementi.\\
			Quindi si definisce una funzione
			$$fl:\mathcal{I}\rightarrow\mathcal{M},$$
			che associa numeri reali $x\in\mathcal{I}$ a numeri di macchina $fl(x)\in\mathcal{M}.$ Quando $x\neq fl(x)$ si commette un \textit{errore di rappresentazione}.\\
			Sia
			$$x=(\alpha_1.\alpha_2\dots\alpha_m\alpha_{m+1}\dots)b^{\eta}$$
			un elemento positivo di $\mathcal{I}$. È possibile rappresentare tale numero
			\begin{itemize}
				\item con troncamento
					$$fl(x)=(\alpha_1.\alpha_2\dots\alpha_m)b^{\eta};$$
				\item con arrotondamento
					$$fl(x)=(\alpha_1.\alpha_2\dots\alpha_{m-1}\tilde{\alpha}_m)b^{\eta},$$
					con
					$$
						\tilde{\alpha}_m =
						\begin{cases}
							\alpha_m, &\quad \text{se $\alpha_{m+1}<\sfrac{b}{2}$,}\\
							\alpha_m+1, &\quad \text{se $\alpha_{m+1}\geq\sfrac{b}{2}$,}
						\end{cases}
					$$
					con eventuali riporti sulle cifre precedenti alla \textit{m}-esima nel caso in cui $\tilde{\alpha}_m\geq b.$
			\end{itemize}
			Infine si impone che $fl(0)=0$ e che $fl(x)=-fl(-x)$, se $x\in\mathcal{I}$ ed $x<0$.
			\begin{teo}
				\label{teor1.4}
				Se $x\in\mathcal{I}$ e $x\neq 0$, allora
				$$fl(x)=x(1+\varepsilon_x),\quad |\varepsilon_x|\leq u,$$
				dove
				$$
					u =
					\begin{cases}
						b^{1-m}, &\quad \text{con troncamento},\\
						\dfrac{1}{2}b^{1-m}, &\quad \text{con arrotondamento}.
					\end{cases}
				$$
			\end{teo}
			\begin{defi}
				La quantità \textit{u}, definita nel Teorema \ref{teor1.4}, è detta \textbf{precisione di macchina}.
			\end{defi}
			
		\subsection{\textit{Overflow} e \textit{Underflow}}
			Quando si cerca di rappresentare un numero reale non contenuto nell'insieme $\mathcal{I}$ definito nella (\ref{insI}) si incorre in particolari tipi di errori:
			\begin{itemize}
				\item se $|x|>r_{max}$\\
					allora l'errore viene chiamato \textbf{overflow} e spesso viene risolto rappresentando i numeri più alti in valore assoluto di $r_{max}$ come una quantità infinita.
				\item se $0<|x|<r_{min}$\\
					si incorre in una condizione d'errore denominata di \textbf{underflow}. Si può risolvere o con la tecnica di \textbf{store 0}, che prevede di rappresentare questi numeri con uno 0, o con la tecnica denominata \textbf{gradual underflow}, che consiste nel denormalizzare la mantissa, includendo quindi nell'insieme $\mathcal{M}$ anche i \textit{numeri di macchina denormalizzati}.
			\end{itemize}
			Riassumendo l'implementazione della funzione $fl$ si ha che
			$$
				fl(x)=
				\begin{cases}
					0,&\quad \text{se $x=0$,}\\
					\tilde{x}\equiv x(1+\varepsilon_x),\quad |\varepsilon_x|\leq u,&\quad \text{se $r_{min}\leq |x|\leq r_{max}$,}\\
					underflow,&\quad \text{se $0<|x|<r_{min}$,}\\
					overflow,&\quad \text{se $|x|>r_{max}$.}
				\end{cases}
			$$
			
		\subsection{Lo standard IEEE 754}
			\label{subSec1.3.4}
			Lo standard per la rappresentazione di numeri reali più diffuso è l'\textit{IEEE 754}, che utilizza una reppresentazione in base $b=2$ ed utilizza una tecnica di arrotondamento definita \textbf{round to even}, ovvero rappresentando $fl(x)$ come il numero di macchina ``più vicino'' ad $x$ (nel caso vi fossero due numeri reali equidistanti viene scelto quello il cui ultimo bit della mantissa è \textit{pari}, ossia 0).\\
			Con questo standard viene guadagnato un bit della mantissa in quanto essa sarà sempre della forma $1.f$, per numeri normalizzati, o della forma $0.f$ per numeri denormalizzati. pertanto viene memorizzata soltanto la \textit{frazione} $f$.\\
			Lo standard si suddivide in due formati: \textit{singola precisione} e \textit{doppia precisione}.\\
			Di seguito è riportato il numero di bit assegnato a ciascun formato\\
			\begin{center}
				\begin{tabular}{c||c|c}
					& Singola precisione & Doppia precisione\\
					\hline
					segno & 1 & 1\\
					\hline
					frazione (mantissa) & 23 (24) & 52 (53)\\
					\hline
					esponente & 8 & 11\\
					\hline
					totale & 32 & 64\\
					\hline
				\end{tabular}
			\end{center}
			Mentre per quanto riguarda l'implementazione dei due formati si ha la seguente tabella:
			\begin{center}
				\begin{tabular}{|c|c|c|}
					\hline
					Singola & Doppia & \multirow{2}{*}{Interpretazione}\\
					precisione & precisione &\\
					\hline
					\multirow{2}{*}{$0<e<255$} & \multirow{2}{*}{$0<e<2047$} & mantissa normalizzata\\
					& & ($\nu=127$ in singola precisione, $\nu=1023$ in doppia)\\
					\hline
					\multicolumn{2}{|c|}{\multirow{2}{*}{$e=0$ e $f\neq 0$}} & mantissa denormalizzata\\
					\multicolumn{2}{|c|}{} & ($\nu=126$ in singola precisione, $\nu=1022$ in doppia)\\
					\hline
					\multicolumn{2}{|c|}{\multirow{2}{*}{$e=f=0$}} & zero\\
					\multicolumn{2}{|c|}{} & (con segno)\\
					\hline
					\multicolumn{2}{|c|}{$f=0$} & infinito\\
					$e=255$ & $e=2047$ & (con segno)\\
					\hline
					\multicolumn{2}{|c|}{$f\neq 0$} & NaN\\
					$e=255$ & $e=2047$ & (Not a Number)\\
					\hline
				\end{tabular}
			\end{center}
			
		\subsection{Aritmetica finita}
			Quando si eseguono delle operazioni in aritmetica finita si deve tenere conto dell'insieme di rappresentabilità.\\
			Per quanto riguarda i numeri interi, se entrambi gli operandi ricadono nell'insieme di rappresentabilità, allora l'implementazione non differisce dalla corrispettiva operazione algebrica.\\
			Se invece si sta operando con numeri reali, allora si deve tener conto che l'implementazione opera tra numeri di macchina e restituisce un numero di macchina come risultato.\\
			Ad esempio l'implementazione della somma algebrica in aritmetica finita sarà:
			\begin{equation}\label{sommaAF}x\oplus y = fl(fl(x) + fl(y),\quad x,y\in\mathbb{R}.\end{equation}
			Ovviamente, in questo secondo caso, proprietà come associatività o distributività possono non valere più.\\
			
		\subsection{Conversione tra tipi diversi}
			Spesso capita di dover convertire un numero intero in un reale e viceversa. La conversione da intero a reale è sempre possibile, introducendo al più un errore dell'ordine di $u$, se il numero di bit della mantissa non bastano a rappresentare il numero (a parità di bit nella rappresentazione come intero e come reale si ha che la mantissa ha meno bit a disposizione rispetto alla rappresentazione come intero). La conversione da reale ad intero è invece, generalmente, più problematica, in quanto il numero che si vuole convertire potrebbe non appartenere all'insieme degli interi rappresentabili $\{-b^N,\dots ,b^N-1\}$, come ad esempio tutti i numeri con virgola.
		
	\section{Condizionamento di un problema}
		\label{sez1.4}
		Sia
		\begin{equation}\label{problDef}y=f(x)\end{equation}
		la formalizzazione di un problema matematico che vogliamo risolvere, con $x\in\mathbb{R}$ dati di ingresso, $f:\mathbb{R}\rightarrow\mathbb{R}$ funzione che descrive formalmente il problema ed $y\in\mathbb{R}$ soluzione del problema.\\
		Quando si decide di risolvere un problema del genere con un calcolatore viene definito un opportuno metodo numerico che risolva il problema in questione, ma di fatto il problema che ci troveremo a risolvere sarà del tipo
		$$\tilde{y}=\tilde{f}(\tilde{x}),$$
		dove $\tilde{x}$ rappresenta i dati in ingresso \textit{perturbati} (cioè con errori di \textit{round-off} o ottenuti sperimentalmente), $\tilde{f}$ indica che il metodo numerico è implementato in aritmetica finita (con eventuali errori di \textit{discretizzazione} o \textit{convergenza}) e $\tilde{y}$ denota i dati in uscita affetti dai precedenti errori.\\
		Ciò che è interessante studiare è il \textbf{condizionamento del problema}, ovvero come gli errori sui dati in ingresso $\varepsilon_x=\dfrac{\tilde{x}-x}{x}$ si propagano attraverso l'esecuzione del metodo numerico fino a definire l'errore $\varepsilon_y=\dfrac{\tilde{y}-y}{y}$ commesso sulla soluzione finale. Per un'analisi più approfondita e completa dell'errore del metodo numerico utilizzato si dovrebbero considerare anche gli errori introdotti dall'utilizzo di $\tilde{f}$ al posto di $f$, tuttavia, per semplicità, ci limitiamo a studiare il problema
		$$\tilde{y}=f(\tilde{x}).$$
		Come accennato precedentemente, se si considerano gli errori relativi sui dati di ingresso e sulla soluzione finale si ha che
		$$\tilde{x}=x(1+\varepsilon_x),\quad\tilde{y}=y(1+\varepsilon_y).$$
		Ciò che ci interessa determinare è, quindi, la relazione che intercorre tra $\varepsilon_x$ e $\varepsilon_y$.\\
		Sviluppando $f(\tilde{x})$ in $x$ si ottiene
		$$f(\tilde{x})=f(x(1+\varepsilon_x))=f(x+x\varepsilon_x)=P_1(x+x\varepsilon_x;x)+O((x\varepsilon_x)^2)=f(x)+f'(x)x\varepsilon_x+O(\varepsilon_x^2),$$
		ovvero
		$$\tilde{y}=y-y\varepsilon_y = f(x)+f'(x)x\varepsilon_x+O(\varepsilon_x^2).$$
		Ricordando la (\ref{problDef}) e considerando un'\textit{analisi al primo ordine} (ovvero trascurando l'errore $O(\varepsilon_x^2)$), si ha che
		$$y+y\varepsilon_y\approx y+f'(x)x\varepsilon_x$$
		$$y\varepsilon_y\approx f'(x)x\varepsilon_x$$
		$$\varepsilon_y\approx f'(x)\dfrac{x}{y}\varepsilon_x$$
		$$|\varepsilon_y|\approx |f'(x)\dfrac{x}{y}|\cdot |\varepsilon_x| \equiv k|\varepsilon_x|.$$
		Quindi si ha che
		\begin{equation}\label{numCond}k \equiv |f'(x)\dfrac{x}{y}|.\end{equation}
		\begin{defi}
			Il \textit{fattore di amplificazione} $k$, che misura di quanto gli errori sui dati iniziali si possono amplificare sull'errore della soluzione finale, è detto \textbf{numero di condizionamento del problema} (\ref{problDef}).
		\end{defi}
		L'ordine di grandezza di $k$ determina quindi il condizionamento del problema:
		\begin{itemize}
			\item se $k\approx 1$, allora l'ordine degli errori finali è uguale a quello degli errori sui dati in ingresso ed il problema si dice \textbf{ben condizionato}.
			\item se $k\gg 1$ significa che nell'eseguire il metodo numerico gli errori finali risultano essere molto più grandi rispetto agli errori sui dati in ingresso. Il problema si dice in questo caso \textbf{malcondizionato}.
		\end{itemize}
		Se un problema risulta avere numero di condizionamento pari a $k\approx u^{-1}$, allora qualunque risultato sarà privo di significato: infatti l'errore sui dati di ingresso sarà dell'ordine di $u$, il che vuol dire che risulterà $\varepsilon_y=1$, che equivale ad una totale perdita di informazione. Se il problema risulta essere malcondizionato l'unica possibilità per ottenere risultati accettabili è quella di riformulare il problema tentando di ottenere un condizionamento migliore; se invece il problema è ben condizionato si deve utilizzare un metodo numerico che risolva il problema mantenendone le buone proprietà di condizionamento (tali metodi numerici sono detti \textit{metodi numericamente stabili}).\\
		Analizziamo il condizionamento delle operazioni algebriche elementari:
		\begin{itemize}
			\item \textbf{\underline{Somma algebrica}}\\
				Il problema in questione è
				$$y=x_1+x_2,\qquad x_1,x_2\in\mathbb{R},\quad x_1+x_2\neq 0.$$
				Siano $\varepsilon_1$ e $\varepsilon_2$ gli errori sui dati in ingresso, si ha
				$$y(1+\varepsilon_y)=x_1(1+\varepsilon_1)+x_2(1+\varepsilon_2)=x_1+x_2+x_1\varepsilon_1+x_2\varepsilon_2.$$
				Si ottiene quindi
				$$y\varepsilon_y=x_1+x_2+x_1\varepsilon_1+x_2\varepsilon_2 -y$$
				$$y\varepsilon_y=x_1+x_2+x_1\varepsilon_1+x_2\varepsilon_2 -x_1-x_2$$
				$$|y\varepsilon_y|=|x_1\varepsilon_1+x_2\varepsilon_2|\leq |x_1\varepsilon_1|+|x_2\varepsilon_2|\leq (|x_1|+|x_2|)\varepsilon_x,\quad\varepsilon_x=max\{|\varepsilon_1|,|\varepsilon_2|\}$$
				\begin{equation}\label{condSomma}|\varepsilon_y|\leq\dfrac{|x_1|+|x_2|}{|y|}\varepsilon_x=\dfrac{|x_1|+|x_2|}{|x_1+x_2|}\varepsilon_x.\end{equation}
				Quindi risulta che
				$$k\leq\dfrac{|x_1|+|x_2|}{|x_1+x_2|}.$$
				Detto questo si possono avere due casi:
				\begin{itemize}
					\item $x_1x_2>0$: se gli addendi sono concordi, allora $k=1$ e la somma è ben condizionata;
					\item $x_1\approx -x_2$: se invece gli addendi sono di segno opposto il numero di condizionamento $k$ può essere arbitrariamente grande, perciò in questo caso la somma è malcondizionata. Questo particolare malcondizionamento, in aritmetica finita, prende il nome di \textit{cancellazione numerica}.
				\end{itemize}
			\item \textbf{\underline{Moltiplicazione}}\\
				Il problema della moltiplicazione di due numeri reali è formulato come segue:
				$$y=x_1x_2,\qquad x_1,x_2\in\mathbb{R},\quad x_1x_2\neq 0$$
				Introducendo gli errori relativi
				$$y(1+\varepsilon_y)=x_1(1+\varepsilon_1)x_2(1+\varepsilon_2)=x_1x_2(1+\varepsilon_1+\varepsilon_2+\varepsilon_1\varepsilon_2).$$
				Trascurando il termine quadratico si ha che
				\begin{align*}
					y\varepsilon_y&\approx x_1x_2(1+\varepsilon_1+\varepsilon_2)-y=\\
					&=x_1x_2(1+\varepsilon_1+\varepsilon_2)-x_1x_2=\\
					&=x_1x_2(\varepsilon_1+\varepsilon_2)
				\end{align*}
				$$\varepsilon_y\approx\dfrac{x_1x_2(\varepsilon_1+\varepsilon_2)}{x_1x_2}=\varepsilon_1+\varepsilon_2$$
				$$|\varepsilon_y|\approx |\varepsilon_1+\varepsilon_2|\leq 2\varepsilon_x,\qquad \varepsilon_x=\{|\varepsilon_1|, |\varepsilon_2|\}.$$
				Quindi il numero di condizionamento risulta essere $k=2$, pertanto la moltiplicazione è sempre ben condizionata.
			\item \textbf{\underline{Divisione}}\\
				Esaminiamo adesso il problema
				$$y=\dfrac{x_1}{x_2},\qquad x_1,x_2\in\mathbb{R},\quad x_1x_2\neq 0.$$
				Si ha che
				\begin{align*}
					y(1+\varepsilon_y)&=\dfrac{x_1(1+\varepsilon_1)}{x_2(1+\varepsilon_2)}=\dfrac{x_1}{x_2}\cdot\dfrac{(1+\varepsilon_1)(1-\varepsilon_2)}{(1+\varepsilon_2)(1-\varepsilon_2)}=\dfrac{x_1}{x_2}\cdot\dfrac{(1+\varepsilon_1)(1-\varepsilon_2)}{(1-\varepsilon_2^2)}\approx\\
					&\approx \dfrac{x_1}{x_2}(1+\varepsilon_1)(1-\varepsilon_2)=\dfrac{x_1}{x_2}(1+\varepsilon_1-\varepsilon_2-\varepsilon_1\varepsilon_2),
				\end{align*}
				dove l'approssimazione è dovuta al fatto che si è trascurato il termine quadratico $\varepsilon_2^2$.\\
				Trascurando anche il termine quadratico $\varepsilon_1\varepsilon_2$ si ottiene quindi
				$$y\varepsilon_y\approx\dfrac{x_1}{x_2}(1+\varepsilon_1-\varepsilon_2)-y$$
				$$y\varepsilon_y\approx\dfrac{x_1}{x_2}(1+\varepsilon_1-\varepsilon_2)-\dfrac{x_1}{x_2}$$
				$$\varepsilon_y\approx\dfrac{x_1}{x_2}(\varepsilon_1-\varepsilon_2)\cdot\dfrac{x_2}{x_1}$$
				$$\varepsilon_y\approx\varepsilon_1-\varepsilon_2$$
				$$|\varepsilon_y|\approx|\varepsilon_1-\varepsilon_2|\leq 2\varepsilon_x,\qquad\varepsilon_x=\{|\varepsilon_1|,|\varepsilon_2|\}.$$
				Anche in questo caso il numero di condizionamento del problema risulta essere $k=2$, quindi la divisione, come la moltiplicazione, è sempre ben condizionata.
		\end{itemize}
		
	\section*{Esercizi}
		\addcontentsline{toc}{section}{Esercizi}
		\markboth{\textsc{\uppercase{Capitolo }\ref{chapterErroriAritmeticaFinita}\uppercase{. Errori ed aritmetica finita}}}{\textsc{\uppercase{Esercizi}}}
		\begin{es} %1.1
			\label{es:1.1}
			Sia $x = \pi \approx 3.1415 = \tilde{x}$. Calcolare il corrispondente errore relativo $\varepsilon_x$. Verificare che il numero di cifre decimali corrette nella rappresentazione approssimata di $x$ mediante $\tilde{x}$ è all'incirca dato da
			$$-\log_{10} |\varepsilon_x|.$$
		\end{es}
		\begin{sol}
			Per definizione di errore relativo si ha che
			$$\varepsilon_x = \dfrac{\tilde{x} - x}{x} = \dfrac{3.1415 - \pi}{pi} \approx -2.9493 \times 10^{-5}$$
			Risulta allora che $-\log_{10}|\varepsilon_x| \approx 4.5303$; infatti 4 è il numero di cifre decimali esatte di 3.1415 come approssimazione di $\pi$ in quanto l'errore assoluto
			$$\Delta x = \tilde{x} - x = 3.1415 - \pi \approx -9.2654 \times 10^{-5}$$
			risulta essere dell'ordine di $10^{-5}$, ovvero ha le prime 4 cifre decimali pari a zero.
			\begin{flushright}
				\underline{Riferimenti \textsc{Matlab}}\\
				Codice \ref{lst:es1.1} (pagina \pageref{lst:es1.1})
			\end{flushright}
		\end{sol}
		\sectionline
		\begin{es} %1.2
			Dimostrare che, se $f(x)$ è sufficientemente regolare e $h > 0$ è una quantità ``piccola'', allora:
			$$\dfrac{f(x_0 + h) - f(x_0 - h)}{2h} = f'(x_0) + O(h^2),$$
			$$\dfrac{f(x_0 + h) -2f(x_0) + f(x_0 - h)}{h^2} = f''(x_0) + O(h^2).$$
		\end{es}
		\begin{sol}
			Per queste due dimostrazioni si deve sviluppare la funzione $f(x)$ mediante un polinomio di Taylor di grado opportuno. Ricordiamo che lo sviluppo in polinomio di Taylor di grado \textit{n} della funzione $f(x)$ centrato in $x_0$ è $P_n(x; x_0) = \sum_{k=0}^{n} \dfrac{(x - x_0)^k}{k!}f^{(k})(x_0)$ e che il resto \textit{n}-esimo vale $R_n(x; x_0) = O(x - x_0)^{n+1}$.\\
			Per la prima uguaglianza si sviluppa $f(x)$ nel polinomio di Taylor al secondo ordine
			\begin{align*}
				f(x) &= P_2(x;x_0)+R_2(x;x_0)=\\
				&=f(x_0) + (x - x_0)f'(x_0) + \dfrac{(x - x_0)^2}{2}f''(x_0) + O((x - x_0)^3).
			\end{align*}
			Calcolando questo sviluppo in $x = (x_0 + h)$ e $x = (x_0 - h)$ si ottiene
			$$f(x_0 + h) = f(x_0) +hf'(x_0) + \dfrac{h^2}{2}f''(x_0) + O(h^3),$$
			$$f(x_0 - h) = f(x_0) -hf'(x_0) + \dfrac{h^2}{2}f''(x_0) + O(h^3).$$
			Quindi sostituendo nel rapporto incrementale di partenza si ha che
			\begin{align*}
				\dfrac{f(x_0 + h) - f(x_0 - h)}{2h} &= \dfrac{f(x_0) + hf'(x_0) + \dfrac{h^2}{2}f''(x_0) + O(h^3)}{2h} +\\
				&-\dfrac{f(x_0) - hf'(x_0) + \dfrac{h^2}{2}f''(x_0) + O(h^3)}{2h} =\\
				&=\dfrac{2hf'(x_0) + o(h^3)}{2h} = f'(x_0) + O(h^2).
			\end{align*}
			Per la seconda uguaglianza è invece necessario utilizzare un'approssimazione con Taylor al terzo ordine
			\begin{align*}
			f(x) &= P_3(x;x_0)+R_3(x;x_0)=\\
			&=f(x_0) + (x - x_0)f'(x_0) + \dfrac{(x - x_0)^2}{2}f''(x_0) +\\
			&+ \dfrac{(x - x_0)^3}{6}f'''(x_0) + O((x - x_0)^4)
			\end{align*}
			e come prima si calcola tale sviluppo in $x = (x_0 + h)$ e $x = (x_0 - h)$
			$$f(x_0 + h) = f(x_0) + hf'(x_0) + \dfrac{h^2}{2}f''(x_0) + \dfrac{h^3}{6}f'''(x_0) + O(h^4),$$
			$$f(x_0 - h) = f(x_0) - hf'(x_0) + \dfrac{h^2}{2}f''(x_0) - \dfrac{h^3}{6}f'''(x_0) + O(h^4).$$
			Quindi sostituendo come nell'uguaglianza precedente si ottiene
			\begin{align*}
				\dfrac{f(x_0 + h) -2f(x_0) + f(x_0 - h)}{h^2} &= \dfrac{h^2f''(x_0) + O(h^4)}{h^2} =\\
				&= f''(x_0) + O(h^2).
			\end{align*}
		\end{sol}
		\sectionline
		\begin{es} %1.3
			\label{es:1.3}
			Dimostrare che il metodo iterativo (\ref{iter}), convergente a $x^*$ (vedi (\ref{conv})), deve verificare la condizione di consistenza
			$$x^* = \Phi (x^*).$$
			Ovvero, la soluzione cercata deve essere un \underline{punto fisso} per la funzione di iterazione che definisce il metodo.
		\end{es}
		\begin{sol}
			Essendo il metodo iterativo convergente, per definizione risulta che
			$$\lim_{x \to +\infty} x_n = x^*.$$
			Supponendo la funzione $\Phi (x_n)$ continua, si ha
			$$\lim_{n \to +\infty} \Phi (x_n) = \Phi (\lim_{n \to +\infty} x_n) = \Phi (x^*),$$
			inoltre, essendo per definizione $\Phi (x_n) = x_{n+1}$,
			$$\lim_{n \to +\infty} \Phi (x_n) = \lim_{x \to +\infty} x_{n+1} = x^*,$$
			da cui la tesi, $x^* = \Phi (x^*).$
		\end{sol}
		\sectionline
		\begin{es} %1.4
			\label{es:1.4}
			Il metodo iterativo
			$$x_{n+1} = \dfrac{x_nx_{n+1} +2}{x_n +x_{n-1}},\quad n=1, 2,\dots,\quad x_0=2, x_1=1.5,$$
			definisce una successione di approssimazioni convergente a $\sqrt{2}$. Calcolare a quale valore si \textit{n} bisogna arrestare l'iterazione, per avere un errore di convergenza $\approx 10^{-12}$. Comparare con i risultati nella seguente tabella
			\begin{center}
				\begin{tabular}{|c|l|}
					\hline
					\textit{n} & $x_n$\\
					\hline
					0 & $2$\\
					1 & $1.5$\\
					2 & $1.416666666666\dots$\\
					3 & $1.414215686274\dots$\\
					4 & $1.414213562374\dots$\\
					\hline
				\end{tabular}
			\end{center}
			relativa all'iterazione
			$$x_{n+1} = \dfrac{1}{2}\left(x_n + \dfrac{2}{x_n}\right),\quad n=0,1,2,\dots,\quad x_0=2.$$
			che approssima $\sqrt{2}.$
		\end{es}
		\begin{sol}
			Risulta che il primo metodo iterativo proposto (quello con i due punti iniziali $x_0$ ed $x_1$) approssima $\sqrt{2}$ con errore di convergenza assoluto dell'ordine di $10^{-12}$ per $i = 6$, come si può vedere dalla tabella seguente
			\begin{center}
				\begin{tabular}{c||l|l}
					\textit{i} & $x_i$ & $\Delta x$\\
					\hline
					0 & $2$ & $5.85786e-001$\\
					1 & $1.5$ & $8.57864e-002$\\
					2 & $1.428571428571\dots$ & $1.43578e-002$\\
					3 & $1.414634146341\dots$ & $4.20583e-004$\\
					4 & $1.414215686274\dots$ & $2.12390e-006$\\
					5 & $1.414213562688\dots$ & $3.15774e-010$\\
					6 & $1.414213562373\dots$ & $0$
				\end{tabular}
			\end{center}
			Per $i \geq 6$ l'errore riportato è 0, probabilmente a causa della precisione di macchina che non riesce a rappresentare numeri troppo ``piccoli''.\\
			Il secondo metodo proposto (quello con il solo punto iniziale $x_0 = 2$) risulta invece raggiungere un errore assoluto di convergenza per $i=4$.\\
			\includegraphics[width=0.8\textwidth]{es1_4.png}
			\begin{flushright}
				\underline{Riferimenti \textsc{Matlab}}\\
				Codice \ref{lst:es1.4} (pagina \pageref{lst:es1.4})
			\end{flushright}
		\end{sol}
		\sectionline
		\begin{es} %1.5
			Il codice Fortran
			\lstinputlisting[language=Fortran, frame=none, stepnumber=0, nolol=true]{code/fortran1_5.txt}
			produce il seguente output:
			\begin{center}
				\begin{tabular}{r r}
					1 & 32765\\
					2 & 32766\\
					3 & 32767\\
					4 & -32768\\
					5 & -32767\\
					6 & -32766\\
					7 & -32765\\
					8 & -32764\\
					9 & -32763\\
					10 & -32762
				\end{tabular}
			\end{center}
			Spiegarne il motivo.
		\end{es}
		\begin{sol}
			Essendo la variabile \textit{numero} di 2 byte significa che il bit più significativo ($\alpha_0$) rappresenta il segno (0 per un numero positivo ed 1 per un numero negativo), mentre i restanti 15 bit (da $\alpha_1$ ad $\alpha_15$) rappresentano il modulo del numero espresso in complemento a 2.\\
			Quando viene stampata la terza iterazione il numero vale 32767, ovvero
			$$\underbrace{0}_+\underbrace{111111111111111}_{32767},$$
			e ci si aspetta quindi che la quarta iterazione stampi il numero 32768. Tuttavia il numero 32768 avrebbe bisogno, per essere rappresentato in binario, di 16 bit per il modulo e di 1 per il segno, per un totale di 17. Infatti, eseguendo la somma in base due si ottiene
			$$\underbrace{1}_-\underbrace{000000000000000}_{32768},$$
			in quanto il riporto viene propagato fino al bit del segno.\\
			Successivamente il numero viene correttamente incrementato.
		\end{sol}
		\sectionline
		\begin{es} %1.6
			\label{es:1.6}
			Dimostrare i Teoremi \ref{teor1.1} e \ref{teor1.3}.
		\end{es}
		\begin{sol}
			\begin{itemize}
				\item \underline{Teorema \ref{teor1.1}}:\\
					Essendo l'insieme $\mathcal{M}$
					$$\mathcal{M}=\{0\}\cup\{\text{numeri della forma (\ref{stringaReale})}\},$$
					risulta che
					$$|\mathcal{M}|=|\{0\}|+|\{\text{numeri della forma (\ref{stringaReale})}\}|.$$
					Per la (\ref{condStringaReale}) si vede che:
					\begin{itemize}
						\item $\alpha_0$ può assumere 2 valori;
						\item $\alpha_1$ può assumere $b-1$ valori;
						\item $\alpha_i$, $\beta_j$ possono assumere \textit{b} valori, per $i=2,\dots,m$, $j=~1,\dots,s$.
					\end{itemize}
					Quindi la cardinalità di $\mathcal{M}$ è data dalle disposizioni con ripetizione di questi elementi, ovvero
					$$|\mathcal{M}|=2(b-1)b^{m+s}+1<+\infty.$$
				\item \underline{Teorema \ref{teor1.3}}:\\
					Per quanto riguarda il minimo numero di macchina, positivo e diverso da 0, si ha che la mantissa minima vale $\rho_{min}=1$, mentre l'esponente minimo vale $\eta_{min}=0-\nu=-\nu$; quindi, applicando la (\ref{numReale})
					$$r_{min} = \rho_{min}b^{\eta_{min}} = 1\cdot b^{-\nu}=b^{-\nu}.$$
					Invece, per quanto riguarda $r_{max}$, si ha che la mantissa è massima quando tutti i suoi bit valgono $(b-1)$, ovvero
					\begin{align*}
						\rho_{max} &= (b-1)\sum_{i=1}^{m}b^{1-i} = (b-1)\sum_{k=0}^{m-1}b^{-k} =\\
						&=(b-1)\sum_{k=0}^{m-1}\left(\dfrac{1}{b}\right)^{k},
					\end{align*}
					ricordando che $\left(1-\dfrac{1}{b}\right)\sum_{k=0}^{m-1}\left(\dfrac{1}{b}\right)^k=1^m-\left(\dfrac{1}{b}\right)^m$, ovvero che $\sum_{k=0}^{m-1}\left(\dfrac{1}{b}\right)^k=b\dfrac{1-b^{-m}}{b-1}$, si ha che
					$$\rho_{max}=b\left(1-b^{-m}\right).$$
					Per quanto riguarda l'esponente massimo, risulta invece
					\begin{align*}
						\eta_{max}&=\left[(b-1)\sum_{i=1}^{s}b^{s-j}\right]-\nu=\left[(b-1)b^{s-1}\sum_{k=0}^{s-1}b^{-k}\right]-\nu=\\
						&=[b^s(1-b^{-s})]-\nu=(b^s-1)-\nu.
					\end{align*}
					Quindi, applicando di nuovo la (\ref{numReale}), si ottiene
					$$r_{max}=b\left(1-b^{-m}\right)b^{b^s-1-\nu} =\left(1-b^{-m}\right)b^{b^s-\nu}.$$
			\end{itemize}
		\end{sol}
		\sectionline
		\begin{es} %1.7
			Dimostrare il Teorema \ref{teor1.4} nel caso della rappresentazione con arrotondamento.
		\end{es}
		\begin{sol}
			Si distinguono i due casi in cui si ha arrotondamento per difetto e per eccesso:
			\begin{itemize}
				\item per difetto:\\
					In questo caso si ha che $\tilde{\alpha}_m=\alpha_m$ in quanto $\alpha_{m+1}<\sfrac{b}{2}$.
					\begin{align*}
						|\varepsilon_x|&=\dfrac{|x-fl(x)|}{|x|}=\dfrac{|(\alpha_1.\alpha_2\dots\alpha_m\alpha_{m+1}\dots-\alpha_1.\alpha_2\dots\tilde{\alpha}_m)b^{\eta}|}{|(\alpha_1.\alpha_2\dots)b^{\eta}|}=\\
						&=\dfrac{|0.\overbrace{0\dots0}^{m-1}\alpha_{m+1}\dots|}{|\alpha_1.\alpha_2\dots|},
					\end{align*}
					quindi, essendo il denominatore sicuramente $\geq 1$, il reciproco sarà sicuramente $\leq 1$. Se poi si trasla il numeratore di $m$ posizioni otteniamo
					$$|\varepsilon_x|\leq|(\alpha_{m+1}.\alpha_{m+2}\dots)b^{-m}|<\dfrac{b}{2}b^{-m}=\dfrac{1}{2}b^{1-m}\equiv u.$$
				\item per eccesso:\\
					In questo caso invece risulta che $\tilde{\alpha}_m=\alpha_m+1$, essendo $\alpha_{m+1}\geq\sfrac{b}{2}$.
					\begin{align*}
						|\varepsilon_x|&=\dfrac{|x-fl(x)|}{|x|}=\dfrac{|(\alpha_1.\alpha_2\dots\alpha_m\alpha_{m+1}\dots-\alpha_1.\alpha_2\dots\tilde{\alpha}_m)b^{\eta}|}{|(\alpha_1.\alpha_2\dots)b^{\eta}|}=\\
						&=\dfrac{|0.\overbrace{0\dots0}^{m-1}\hat{\alpha}_{m+1}\dots|}{|\alpha_1.\alpha_2\dots|},
					\end{align*}
					con $\hat{\alpha}_{m+1}=\tilde{\alpha}_m0-\alpha_m\alpha_{m+1}\leq\sfrac{b}{2}$.\\
					In questo caso però è possibile che il valore assoluto al numeratore, traslato di $m$ posizioni, sia $>\sfrac{b}{2}$, come ad esempio nel caso estremo in cui $\hat{\alpha}_{m+1}=\sfrac{b}{2}$ e tutte le cifre successive valgono $(b-1)$. Quando si verifica questo si nota, tuttavia, che dividendo tale quantità per il valore assoluto al denominatore si ottiene sicuramente una quantità $<\sfrac{b}{2}$.\\
					Quando invece il valore assoluto al numeratore (traslato di $m$ posizioni) risulta già essere $\leq\sfrac{b}{2}$ si procede come nel caso precedente per difetto.\\
					Quindi in ogni caso si ha che
					$$|\varepsilon_x|\leq\dfrac{b}{2}b^{-m}=\dfrac{1}{2}b^{1-m}\equiv u.$$
			\end{itemize}
		\end{sol}
		\sectionline
		\begin{es} %1.8
			\label{es:1.8}
			Quante cifre binarie sono utilizzate per rappresentare, mediante arrotondamento, la mantissa di un numero, sapendo che la precisione di macchina è $u\approx 4.66\cdot 10^{-10}$?
		\end{es}
		\begin{sol}
			Applicando il Teorema \ref{teor1.4} si ha che $u=\dfrac{1}{2}b^{1-m}$, ovvero che
			$$m=1-\log_b2u.$$
			Ponendo $b=2$ e $u=4.66\cdot 10^{-10}$ e arrotondando, eventualmente, per eccesso, risulta
			$$m=-\log_24.66\cdot 10^{-10}\approx 31.$$
			Quindi servono almeno 31 cifre binarie per la mantissa per avere una precisione di macchina non superiore a $4.66\cdot 10^{-10}$.
			\begin{flushright}
				\underline{Riferimenti \textsc{Matlab}}\\
				Codice \ref{lst:es1.8} (pagina \pageref{lst:es1.8})
			\end{flushright}
		\end{sol}
		\sectionline
		\begin{es} %1.9
			Dimostrare che, detta $u$ la precisione di macchina utilizzata,
			$$-\log_{10}u$$
			fornisce, approssimativamente, il numero di cifre decimali correttamente rappresentate nella mantissa.
		\end{es}
		\begin{sol}
			Studiamo separatamente i casi in cui la rappresentazione avviene tramite troncamento e tramite arrotondamento.\\
			\begin{itemize}
				\item con troncamento:\\
					Per il Teorema \ref{teor1.4}, posto $b=10$, si ha che
					$$u=10^{1-m}\Rightarrow \log_{10}u=1-m\Rightarrow m=1-\log_{10}u\approx -\log_{10}u.$$
				\item con arrotondamento:\\
					Sempre per il Teorema \ref{teor1.4}, con $b=10$,
					\begin{align*}
						u&=\dfrac{1}{2}10^{1-m}\Rightarrow\log_{10}2u=1-m\Rightarrow\\
						&
						\begin{aligned}
							\Rightarrow m&=1-\log_{10}2u=1-\log_{10}2-\log_{10}u=\\
							&=\log_{10}5-\log_{10}u\approx -\log_{10}u.
						\end{aligned}
					\end{align*}
			\end{itemize}
		\end{sol}
		\sectionline
		\begin{es} %1.10
			\label{es:1.10}
			Con riferimento allo standard \textit{IEEE 754} (vedi Sezione \ref{subSec1.3.4}) determinare, relativamente alla doppia precisione:
			\begin{enumerate}
				\item il più grande numero di macchina,
				\item il più piccolo numero di macchina normalizzato positivo,
				\item il più piccolo numero di macchina denormalizzato positivo,
				\item la precisione di macchina.
			\end{enumerate}
			Confrontare le risposte ai primi due quesiti col risultato fornito dalle function \textsc{Matlab} \lstinline{realmax} e \lstinline{realmin}.
		\end{es}
		\begin{sol}
			\begin{enumerate}
				\item Si ha che il più grande numero di macchina in doppia precisione è dato dalla mantissa massima e l'esponente massimo. Per l'Esercizio \ref{es:1.6} si ha che $\rho=b(1-b^{-m})=2(1-2^{-53})=2-2^{-52}$, mentre $\eta=2046-\nu=2046-1023=1023$, essendo il valore $e=2047$ riservato.\\
					Quindi il massimo numero di macchina risulta essere
					$$r_{max}=(2-2^{-52})2^{1023}\approx 1.8\cdot 10^{308},$$
					infatti la function \lstinline{realmax} di \textsc{Matlab} restituisce lo stesso risultato.
				\item Per quanto riguarda il più piccolo numero di macchina normalizzato positivo basta applicare la (\ref{rMinMax}), con l'accortezza che l'esponente $e=0$ è riservato e quindi il più piccolo esponente risulta essere $e=1$:
					$$r_{minN}=2^{1-\nu}=2^{1-1023}=2^{-1022}\approx 2.2\cdot 10^{-308}.$$
					Utilizzando la function \textsc{Matlab} \lstinline{realmin} si perviene allo stesso risultato.
				\item Il più piccolo numero di macchina denormalizzato positivo è caratterizzato, per definizione, dall'esponente $e=0$ e dalla mantissa minima diversa da 0, ovvero la mantissa che ha tutti i bit, tranne il meno significativo, a 0, che vale $\rho=2^{-52}$.\\
					Quindi
					$$r_{minD}=2^{-52}2^{0-\nu}=2^{-52}2^{-1022}\approx 4.9\cdot 10^{-324}.$$
				\item Dal momento che lo standard \textit{IEEE 754} utilizza la rappresentazione con arrotondamento, per il Teorema \ref{teor1.4} si ha
					$$u=\dfrac{1}{2}b^{1-m}=\dfrac{1}{2}2^{1-53}=2^{-53}\approx 1.1\cdot 10^{-16}.$$
			\end{enumerate}
			\begin{flushright}
				\underline{Riferimenti \textsc{Matlab}}\\
				Codice \ref{lst:es1.10} (pagina \pageref{lst:es1.10})
			\end{flushright}
		\end{sol}
		\sectionline
		\begin{es} %1.11
			\label{es:1.11}
			Eseguire le seguenti istruzioni \textsc{Matlab}:
			\lstinputlisting[frame=none, stepnumber=0, nolol=true]{code/matlab1_11.m}
			Spiegarne il (non) funzionamento.
		\end{es}
		\begin{sol}
			Si nota che la rappresentazione in binario di $0.1$ è infinita periodica, in particolare vale $0.0\overline{0011}$, in quanto la frazione corrispondente $\sfrac{1}{10}$ non ha soltanto 2 come fattore primo del denominatore.\\
			Il valore memorizzato nel calcolatore della variabile \textit{delta}, e quindi il valore di $x$ alla prima iterazione, risulta essere $1\underbrace{0011\dots 0011}_{12 volte}001$ per la mantissa, che ricordiamo dev'essere normalizzata, e $\eta=-4$, che corrisponde all'esponente $e=\nu+\eta=1023-4=1019=01111111011_{[2]}$. Questa quantità vale esattamente
			\begin{align*}
				r=0.&099999999999999993859642133668346\\
				&539081847127121849822415277933499\\
				&7546040964300101522745446966427383,
			\end{align*}\\
			ed è quindi minore di $0.1$.\\
			Risulta quindi che alla decima iterazione il valore memorizzato di $x$ è $0.\underbrace{1\dots 1}_{52 volte}<1_{[10]}$ mentre all'undicesima si ha $x=1.0\underbrace{0011\dots 0011}_{12 volte}001>1_{[10]}$. Quindi $x$ non assume mai il valore 1 e di conseguenza il ciclo è infinito.\\
			Per far funzionare il codice si può utilizzare il comando \textsc{Matlab} \lstinline{eps}, che restituisce lo spazio presente tra i numeri di macchina, ovvero la precisione di macchina, come guardia per la terminazione del ciclo, imponendo che il ciclo termini quando \lstinline{abs(x-1)<=eps}, che corrisponde all'impostare una tolleranza come criterio d'arresto.
			\begin{flushright}
				\underline{Riferimenti \textsc{Matlab}}\\
				Codice \ref{lst:es1.11} (pagina \pageref{lst:es1.11})
			\end{flushright}
		\end{sol}
		\sectionline
		\begin{es} %1.12
			\label{es:1.12}
			Individuare l'algoritmo più efficace per calcolare, in aritmetica finita, l'espressione $\sqrt{x^2 + y^2}$.
		\end{es}
		\begin{sol}
			L'espressione risulta essere condizionata in quanto i due elevamenti a potenza si possono ricondurre a due moltiplicazioni ($x^2=x\cdot x$ e $y^2=y\cdot y$), che sono sempre ben condizionate (con $k=2$); la somma risulta essere tra addendi concordi (entrambi positivi), quindi anch'essa ben condizionata (con $k=1$); ed infine l'estrazione della radice quadrata risulta ben condizionata (con $k=\sfrac{1}{2}$).\\
			Il problema in cui si può incorrere quando si tenta di valutare quest'espressione in aritmetica finita è che si verifichi un \textit{overflow}: infatti se prendiamo, ad esempio, $x=10^{200}$ ed $y=10^{200}$ si ha che il risultato è $\sqrt{2}\cdot 10^{200}$ il quale, se si utilizza lo standard \textit{IEEE 754} con doppia precisione, rientra nell'insieme dei numeri di macchina, essendo il massimo numero di macchina rappresentabile con questo formato $\approx 1.8\cdot 10^{308}$ (vedi Esercizio \ref{es:1.10}). Tuttavia l'elevamento a potenza produce il valore $10^{400}$ che, non rientrando nell'insieme dei numeri di macchina, causa un \textit{overflow}.\\
			Se si suppone, senza perdita di generalità, che $x>y$, una soluzione consiste nel portare fuori dalla radice l'ordine di grandezza di $x$
			$$\sqrt{x^2 + y^2}=\sqrt{x^2(1 +\dfrac{y^2}{x^2})}=|x|\sqrt{1+\left(\dfrac{y}{x}\right)^2}.$$
			In questo modo si ha che l'espressione è correttamente calcolata (utilizzando i valori precedenti) $\sqrt{2}\cdot 10^{200}$ anziché \textit{Inf} e l'espressione rimane ben condizionata, in quanto la divisione è un'operazione sempre ben condizionata (con $k=2$).\\
			Per valori molto grandi di $x$ e molto piccoli di $y$ si può incorrere nel problema opposto, ovvero un \textit{underflow}. Tuttavia questo problema è considerato meno grave in quanto può essere risolto denormalizzando il numero in floating point.
			\begin{flushright}
				\underline{Riferimenti \textsc{Matlab}}\\
				Codice \ref{lst:es1.12} (pagina \pageref{lst:es1.12})
			\end{flushright}
		\end{sol}
		\sectionline
		\begin{es} %1.13
			Eseguire le seguenti istruzioni \textsc{Matlab}:
			\lstinputlisting[frame=none, stepnumber=0, nolol=true]{code/matlab1_13.m}
			Concludere che la somma algebrica non gode, in aritmetica finita, della proprietà associativa.
		\end{es}
		\begin{sol}
			Il comando \textsc{Matlab} \lstinline{eps}, senza argomenti, restituisce la distanza tra 1 ed il primo numero maggiore di 1 in doppia precisione, ovvero $2^{-52}\approx 2.22\cdot 10^{-16}$.\\
			Quando, nella prima espressione, il valore di \lstinline{eps} viene dimezzato e poi sommato ad 1, si ottiene un valore che è a metà tra 1 ed $1+eps$, ovvero un numero non rappresentabile con la doppia precisione, che viene quindi interpretato come 1. Questo passaggio provoca l'errore, in quanto viene persa una quantità pari ad $\sfrac{eps}{2}$, restituendo come risultato 0.\\
			La seconda espressione, invece, viene valutata correttamente 1 in aritmetica finita in quanto, dando priorità alla sottrazione $(1-1)$ si ha che il valore $\sfrac{eps}{2}$ viene correttamente moltiplicato per il suo reciproco, restituendo, appunto, 1.\\
			Da questo semplice esempio si evince che, in aritmetica finita, la somma algebrica non gode, in generale, della proprietà associativa.
		\end{sol}
		\sectionline
		\begin{es} %1.14
			Eseguire e discutere il risultato delle seguenti istruzioni \textsc{Matlab}:
			\lstinputlisting[frame=none, stepnumber=0, nolol=true]{code/matlab1_14.m}
		\end{es}
		\begin{sol}
			Le due espressioni sono algebricamente equivalenti (per la proprietà distributiva del prodotto rispetto alla sottrazione), tuttavia la valutazione della prima restituisce, correttamente, il valore 0, mentre la seconda da come risultato \textit{NaN}, che sta per \textit{Not a Number}.\\
			Questo è dovuto al fatto che mentre nella prima espressione viene subito calcolato il valore 0, che annullerà anche il secondo fattore della moltiplicazione, nella seconda espressione viene eseguita prima la moltiplicazione e poi la sottrazione. Risulta quindi che la valutazione di $10^{300}\cdot 10^{300}$ viene interpretata come \textit{Inf}, ovvero un valore infinito, in quanto il valore effettivo $10^{600}$ non è rappresentabile in doppia precisione (più precisamente si verificano due overflow). La sottrazione degenera quindi nella forma indeterminata $[\infty - \infty]$, restituendo \textit{NaN} come valore.\\
			Da questo esempio si può dedurre che, in aritmetica finita, non vale la proprietà distributiva del prodotto rispetto alla sottrazione (e ragionevolmente la proprietà distributiva in generale).
		\end{sol}
		\sectionline
		\begin{es} %1.15
			Eseguire l'analisi dell'errore (relativo), dei due seguenti algoritmi per calcolare la somma di tre numeri (vedi (\ref{sommaAF})):
			$$1)\quad (x\oplus y)\oplus z,\qquad 2)\quad x\oplus(y\oplus z).$$
		\end{es}
		\begin{sol}
			L'espressione in aritmetica esatta è equivalente nei due casi ed è data da $R = (x+y)+z = x+(y+z)=x+y+z$.
			\begin{itemize}
				\item
					Nel primo caso si ha che l'espressione in aritmetica finita è data da
					\begin{align*}
						F_1&=(x\oplus y)\oplus z=\\
						&=fl(fl(fl(fl(x)+fl(y)))+fl(z))=\\
						&=[(x(1+\varepsilon_x)+y(1+\varepsilon_y))(1+\varepsilon_A)+z(1+\varepsilon_z)](1+\varepsilon_B).
					\end{align*}
					Quindi l'errore relativo, tenendo conto che $u\geq u^2\geq u^3$, è dato da
					\begin{align*}
						\varepsilon_1&=\dfrac{F_1-R}{R}=\\
						&=[(x(1+\varepsilon_x)+y(1+\varepsilon_y))(1+\varepsilon_A)+z(1+\varepsilon_z)](1+\varepsilon_B)=\\
						&=\dfrac{x(1+\varepsilon_x)(1+\varepsilon_A)(1+\varepsilon_B) + y(1+\varepsilon_y)(1+\varepsilon_A)(1+\varepsilon_B)}{x+y+z}+\\
						&\quad +\dfrac{z(1+\varepsilon_z)(1+\varepsilon_B) -x-y-z}{x+y+z}\leq\\
						&\leq \dfrac{x(1+u)^3 + y(1+u)^3 + z(1+u)^2 -x-y-z}{x+y+z}=\\
						&=\dfrac{x(3u+3u^2+u^3) + y(3u+3u^2+u^3) +z(2u+u^2)}{x+y+z}\leq\\
						&\leq\dfrac{7ux+7uy+3uz}{x+y+z}=\\
						&=u\left(3+4\dfrac{x+y}{x+y+z}\right).
					\end{align*}
				\item
					Analogamente per il secondo caso si ha che l'espressione in aritmetica finita è data da
					\begin{align*}
						F_2&=x\oplus (y\oplus z)=\\
						&=[x(1+\varepsilon_x)+(y(1+\varepsilon_y)+z(1+\varepsilon_z))(1+\varepsilon_C)](1+\varepsilon_D),
					\end{align*}
					e quindi l'errore relativo corrispondente è dato da
					$$\varepsilon_2=\dfrac{F_2-R}{R}=u\left(3+4\dfrac{y+z}{x+y+z}\right).$$
			\end{itemize}
			Si nota che l'unico modo per far diminuire l'errore relativo è di diminuire il numeratore, ovvero la quantità $(x+y)$, nel primo caso, e $y+z$ nel secondo. Quindi se ne deduce che, anche se in aritmetica esatta le due espressioni sono equivalenti, in aritmetica finita l'espressione migliore (ovvero quella che presenterà un minor errore sul risultato) sarà quella che somma per primi i due addendi con valore minore tra i tre presenti nell'espressione.
		\end{sol}
		\sectionline
		\begin{es} %1.16
			Dimostrare che il numero di condizionamento del problema del calcolo di $y=\sqrt{x}$ è $k=\sfrac{1}{2}$.
		\end{es}
		\begin{sol}
			Applicando la (\ref{numCond}), in questo caso specifico si ha $y=f(x)=\sqrt{x}$ ed $f'(x)=\dfrac{1}{2\sqrt{x}}$.\\
			Quindi risulta che
			$$k=\left|\dfrac{1}{2\sqrt{x}}\cdot\dfrac{x}{\sqrt{x}}\right|=\left|\dfrac{1}{2}\cdot\dfrac{x}{x}\right|=\dfrac{1}{2}.$$
			L'estrazione da radice quadrata risulta quindi essere sempre ben condizionata.
		\end{sol}
		\sectionline
		\begin{es}[Cancellazione Numerica] %1.17
			\label{es:1.17}
			Si supponga di dover calcolare l'espressione
			$$y=0.12345678-0.12341234\equiv 0.00004444,$$
			utilizzando una rappresentazione decimale con arrotondamento alla quarta cifra significativa. Comparare il risultato esatto con quello ottenuto in aritmetica finita, e determinare la perdita di cifre significative derivante dalla operazione effettuata. Verificare che questo risultato è in accordo con l'analisi di condizionamento (vedi (\ref{condSomma})).
		\end{es}
		\begin{sol}
			Il problema in questione è una somma algebrica con addendi discordi, in particolare
			$$x_1=0.12345678,\qquad x_2=-0.12341234,\qquad y=x_1+x_2=0.00004444.$$
			Arrotondando $x_1$ ed $x_2$ alla quarta cifra decimale si ottengono i dati di ingresso perturbati
			$$\tilde{x_1}=0.1235,\qquad\tilde{x_2}=-0.1234,$$
			e la corrispondente soluzione del problema in aritmetica finita è calcolata come somma dei due addendi perturbati
			$$\tilde{y}=\tilde{x_1}+\tilde{x_2}=0.0001.$$
			Calcoliamo adesso gli errori relativi
			$$\varepsilon_1=\dfrac{\tilde{x_1}-x_1}{x_1}=\dfrac{0.1235-0.12345678}{0.12345678}\approx 3.5\cdot 10^{-4}$$
			$$\varepsilon_2=\dfrac{\tilde{x_2}-x_2}{x_2}=\dfrac{-0.1234+0.12341234}{-0.12341234}\approx -9.9\cdot 10^{-5}$$
			$$\varepsilon_y=\dfrac{\tilde{y}-y}{y}=\dfrac{0.0001-0.00004444}{0.00004444}\approx 1.25.$$
			Risulta quindi che il risultato ottenuto è privo di significato in quanto l'errore relativo sulla soluzione maggiore di $1$ implica una perdita totale di informazione. Ne consegue che sono state perse tutte le cifre significative della soluzione.\\
			Applicando la (\ref{condSomma}) si ha che
			$$k=\dfrac{|x_1|+|x_2|}{|x_1+x_2|}=\dfrac{0.12345678+0.12341234}{0.00004444}\approx 5.6\cdot 10^{3}$$
			$$\varepsilon_x=max\{|\varepsilon_1|, |\varepsilon_2|\}=|\varepsilon_1|\approx 3.5\cdot 10^{-4}.$$
			Si vede quindi che, essendo il numero di condizionamento del problema $k\gg 1$, il problema risulta malcondizionato.\\
			Se si prova a moltiplicare l'errore relativo massimo sui dati di ingresso $\varepsilon_x$ per il fattore di amplificazione calcolato $k$, si ottiene una maggiorazione dell'errore relativo sulla soluzione, che non si discosta di molto dal valore effettivamente calcolato
			$$k\varepsilon_x\approx 5.6\cdot 10^{3}\cdot 3.5\cdot 10^{-4}\approx 1.9\approx 1.25 \approx \varepsilon_y.$$
			\begin{flushright}
				\underline{Riferimenti \textsc{Matlab}}\\
				Codice \ref{lst:es1.17} (pagina \pageref{lst:es1.17})
			\end{flushright}
		\end{sol}
		\sectionline
		\begin{es}[Cancellazione Numerica] %1.18
			\label{es:1.18}
			Eseguire le seguenti istruzioni in \textsc{Matlab}:
			\lstinputlisting[frame=none, stepnumber=0, nolol=true]{code/matlab1_18.m}
			Valutare l'errore relativo sui dati di ingresso e l'errore relativo sul risultato ottenuto.
		\end{es}
		\begin{sol}
			Essendo gli addendi discordi e circa uguali in modulo, si ha che il problema è malcondizionato. Infatti il numero di condizionamento del problema vale
			$$k=\dfrac{|a|+|-b|}{|a-b|}=\dfrac{0.1+0.099999999999}{0.000000000001}\approx 2\cdot 10^{11}.$$
			Se si considera che i dati in ingresso sono affetti da un errore relativo dell'ordine della precisione di macchina, ovvero $\varepsilon_x=u\approx 1.1\cdot 10^{-16}$ (con doppia precisione, vedi Esercizio \ref{es:1.10}), allora l'errore relativo sulla soluzione finale sarà dell'ordine di
			$$\varepsilon_y\approx k\varepsilon_x \approx 2\cdot 10^{11}\cdot 1.1\cdot 10^{-16}\approx 2.2\cdot 10^{-5}.$$
			Infatti si ha che eseguendo il codice \textsc{Matlab} proposto risultano corrette (cioè 0) soltanto le prime $5$ cifre della soluzione, come si evince anche dal fatto che
			$$\lceil-\log_{10}|\varepsilon_y|\rceil \approx\lceil -\log_{10}(2.2\cdot 10^{-5})\rceil = 5.$$
			\begin{flushright}
				\underline{Riferimenti \textsc{Matlab}}\\
				Codice \ref{lst:es1.18} (pagina \pageref{lst:es1.18})
			\end{flushright}
		\end{sol}
		
	\section*{Codice degli esercizi}
		\addcontentsline{toc}{section}{Codice degli esercizi}
		\markboth{\textsc{\uppercase{Capitolo }\ref{chapterErroriAritmeticaFinita}\uppercase{. Errori ed aritmetica finita}}}{\textsc{\uppercase{Codice degli esercizi}}}
		\lstinputlisting[caption={Esercizio \ref{es:1.1}.}, label=lst:es1.1]{code/es1_1.m}
		\sectionline
		\lstinputlisting[caption={Esercizio \ref{es:1.4}.}, label=lst:es1.4]{code/es1_4.m}
		\sectionline
		\lstinputlisting[caption={Esercizio \ref{es:1.8}.}, label=lst:es1.8]{code/es1_8.m}
		\sectionline
		\lstinputlisting[caption={Esercizio \ref{es:1.10}.}, label=lst:es1.10]{code/es1_10.m}
		\sectionline
		\lstinputlisting[caption={Esercizio \ref{es:1.11}.}, label=lst:es1.11]{code/es1_11.m}
		\sectionline
		\lstinputlisting[caption={Esercizio \ref{es:1.12}.}, label=lst:es1.12]{code/es1_12.m}
		\sectionline
		\lstinputlisting[caption={Esercizio \ref{es:1.17}.}, label=lst:es1.17]{code/es1_17.m}
		\sectionline
		\lstinputlisting[caption={Esercizio \ref{es:1.18}.}, label=lst:es1.18]{code/es1_18.m}
		