\chapter*{Implementazione}

Il progetto che abbiamo realizzato prevede l'implementazione dell'algoritmo \textbf{RankBoost} all'interno del framework QuickRank, utilizzando C++ come linguaggio di programmazione. In seguito sono stati effettuati anche dei test di comparazione con altri algoritmi presenti nei software Quickrank, jForests, RT-Rank e RankLib.\\
È stata, dunque, inizialmente implementata una versione sequenziale dell'algoritmo RankBoost all'interno di custom\_ltr.cc. Prima di far partire l'algoritmo, tuttavia, è stato necessario creare un metodo init() per permetta di inizializzare tutte le varie strutture dati che poi verranno utilizzate in seguito. All'interno del metodo init() vengono anche controllati l'orientamento dei dataset che sono stati passati come parametri al metodo learn(). Se, infatti, l'orientamento dei dataset non è orizzontale, allora tali dataset vengono opportunamente trasformati in dataset con orientamento orizzontale (istanze x features).\\
Il ``\textbf{cuore}'' principale dell'algoritmo RankBoost risiede nel metodo learn() ed, in particolare, all'interno del ciclo for che si occupa di scandire le varie iterazioni. Ad ogni iterazione, infatti, viene calcolato \textit{alpha} (peso del weak ranker) e vengono utilizzati i metodi \textit{compute\_pi} e \textit{compute\_weak\_ranker} per calcolare, rispettivamente, la matrice potenziale ed il Weak Ranker migliore che poi verrà utilizzato per aggiornare la matrice distribuzione D.\\
Le metriche relative ai dataset di training e validation vengono calcolate durante le varie iterazioni ed il risultato viene stampato al termine del ciclo for. Non sapevamo, inizialmente, se fosse corretto fare ciò, ovvero calcolare le metriche relative al training ed al validation durante le varie iterazioni dell'algoritmo anziché in seguito dopo la terminazione delle varie iterazioni. Tuttavia, calcolando gli score relativi al training ed al validation iterazione per iterazione, riusciamo ad evitare di dover effettuare ulteriori cicli.\\
Per poter gestire più semplicemente i vari Weak Ranker è stata creata una subclasse \textbf{Weak Ranker} all'interno di \textit{custom\_ltr.h} e caratterizzata dalle variabili \textit{theta}, \textit{feature\_id} e \textit{sign} e dai metodi \textit{clone()}, utile per creare un nuovo Weak Ranker con gli stessi valori del Weak Ranker corrente, \textit{get\_feature\_id()}, \textit{get\_theta()} e \textit{score\_document}().\\
Dopo aver verificato il corretto funzionamento di tale implementazione, abbiamo provveduto a parallelizzare alcune porzioni del codice utilizzando il tool \textbf{OpenMP}. \\
In alcuni casi, le versioni sequenziali di alcune porzioni del codice risultano migliori in termini di velocità di esecuzione rispetto alle rispettive versioni parallele e, pertanto, non sono state parallelizzate. Metodi come \textit{compute\_weak\_ranker}, invece, hanno ottenuto un significato incremento delle prestazioni.\\
Abbiamo provveduto anche ad analizzare le prestazioni dell'algoritmo utilizzando le varie tipologie di scheduling parallelo: \textit{guided}, \textit{dynamic} e \textit{static}. Lo scheduling \textit{dynamic} è risultato il migliore tra le varie tipologie di scheduling e, per questo motivo, abbiamo provveduto a modificare la variabile di sistema \textit{OMP\_SCHEDULE} in modo che tutte le porzioni di codice parallelizzate utilizzino lo scheduling di tipo \textit{dynamic}. Similmente, abbiamo provveduto ad utilizzare la variabile \textit{n\_thread} (dichiarata in \textit{custom\_ltr.h}) per poter gestire più semplicemente il numero di thread creati in ogni porzione di codice parallela.

	\section*{Problemi incontrati}

I principali problemi riscontrati nell'implementare l'algoritmo RankBoost sono sorti al momento della parallelizzazione ed, in particolare, all'interno del metodo \textit{compute\_weak\_ranker}. Parallelizzare il ciclo più esterno, ad esempio, portava a risultati differenti (e spesso erronei) rispetto alla versione sequenziale dell'algoritmo. Ciò non avveniva, tuttavia, se il ciclo parallelizzato era il ciclo più interno. In tal caso, infatti, sono stati ottenuti gli stessi risultati della versione sequenziale, pur osservando uno speedup notevole. Tale comportamento era inusuale ed, infatti, è stato risolto semplicemente effettuando una gestione più opportuna delle variabili condivise.\\
Una mal gestione delle \textbf{variabili condivise} aveva portato anche ad ottenere risultati non deterministici sia in termini di tempo di esecuzione dell'algoritmo, sia in termini di valori di NDCG. La principale causa di tale comportamento è stata individuata nella mancata dichiarazione della Feature \textit{Feat} (variabile d'appoggio durante il calcolo del weak ranker) di tipo \textit{firstprivate}.\\
Un'altra situazione controversa che abbiamo affrontato durante l'implementazione di tale algoritmo riguarda la gestione di \textbf{R} all'interno del metodo \textit{compute\_weak\_ranker}. Seguendo le slides del corso, infatti, avevamo inizialmente implementato il metodo \textit{compute\_weak\_ranker} in modo da avere valori di R crescenti durante le varie iterazioni effettuate dall'algoritmo. Tale discorso, infatti, era consistente con il concetto di bontà (o \textit{goodness}) del weak ranker.\\
Confrontando i risultati da noi ottenuti con i risultati della libreria Java \textbf{RankLib} abbiamo potuto notare che, in RankLib, i valori di R non sono crescenti, bensì decrescenti e che questo non viene associato alla \textbf{bontà} del weak ranker, bensì all'\textbf{errore}. Tale comportamento deriva principalmente dal mancato controllo degli R negativi all'interno del metodo che provvede al calcolo del weak ranker.\\
Abbiamo, dunque, provato a commentare (e dunque eliminare) la porzione di codice che si occupava di effettuare il suddetto controllo (in \textit{compute\_weak\_ranker}) ed abbiamo registrato, oltre ai valori decrescenti di R, anche valori di NDCG molto maggiori rispetto a prima. Abbiamo avuto delle difficoltà ad interpretare il corretto significato di R: se seguivamo le slides del corso ottenevamo valori di R crescenti ed NDCG più bassi, se seguivamo invece RankLib ottenevamo R descrescenti ed NDCG più alti. Riscontrando valori di NDCG più alti senza l'utilizzo di un controllo sugli R negativi, abbiamo preferito adottare tale approccio.\\
Un altro dubbio che abbiamo avuto durante la fase di implementazione dell'algoritmo riguarda il significato del campo \textbf{offset}, in particolare all'interno del metodo \textit{score\_document}. Ogni algoritmo, infatti, potrebbe aver bisogno di lavorare con un orientamento differente del dataset (orizzontale o verticale). Il campo offset indica solamente la posizione della prossima feature all'interno dello stesso documento e serve, appunto, ad ottenere un accesso più diretto ed efficace ai dati. Nel caso di orientamento orizzontale del dataset (documenti x features), la seconda feature è immediatamente dopo la prima e dunque il campo \textit{offset} = 1. Nel caso di orientamento verticale del dataset (features x documenti), invece, il campo offset è uguale al numero di documenti del dataset poiché, per trovare la feature successiva, occorre prima scorrere tutti i documenti relativi alla feature precedente.\\

	\section*{Speedup e miglioramenti}
Allo scopo di velocizzare l'algoritmo sono state introdotte le strutture dati \textbf{SDF} (Sorted Document Features) e \textbf{last}.\\
In particolare, la matrice \textbf{SDF} contiene, per ogni features e per ogni query, gli indici dei documenti ordinati in senso decrescente. Tale matrice viene inizializzata all'interno del metodo \textit{init()} e viene utilizzata soprattutto all'interno del metodo \textit{compute\_weak\_ranker} per poter calcolare in maniera più efficiente lo weak ranker migliore per ogni feature.\\
Il vettore \textbf{last}, invece, conterrà l'ultima posizione considerata nei documenti di ogni query ed è particolarmente utile all'interno del metodo \textit{compute\_weak\_ranker} per poter ``saltare'' tutti i documenti già precedentemente considerati ed evitare, dunque, inutili iterazioni. È possibile fare ciò, naturalmente, grazie alla presenza ed all'utilizzo della matrice SDF che permette di avere i documenti ordinati in senso decrescente.
