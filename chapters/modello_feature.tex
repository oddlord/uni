\section*{Modello e feature}

Il funzionamento dello script è variato molto dalla sua prima versione ed è in costante aggiornamento.\\
\\
Nelle prime versioni si è provato a fare una \textbf{media} globale e quindi una media per store delle vendite in fase di training, per poi usare tali medie come predizione in fase di testing. In questi casi il valore dell'errore \textit{rmspe} era attorno a $0.25$.\\
\\
Successivamente si è provato ad utilizzare il pacchetto \textit{sklearn}, che fornisce molti strumenti per il Data Mining.\\
La prima prova con \textit{sklearn} è stata di utilizzare un \textit{LinearRegressor} come modello, passandogli un po' tutti i campi del trainset come feature. In particolare si scelsero come feature \textit{Store}, \textit{DayOfWeek}, \textit{Promo}, \textit{StateHoliday} e \textit{SchoolHoliday}. Veniva utilizzato anche il campo \textit{Open} ma non come feature vera e propria, ma per settare direttamente la predizione a $0$ nel caso in cui lo store fosse chiuso (store chiusi in fase di training non venivano considerati). Questo primo approccio con \textit{sklearn} dette risultati molto bassi (intorno a $0.45$), addirittura peggiori delle medie fatte inizialmente.\\
Si è quindi cambiato il modello con un altro regressore, ovvero il \textbf{KNeighborsRegressor}, utilizzando le stesse feature di prima: in questo caso i risultati sono notevolmente migliorati, ottenendo un \textit{rmspe} di circa $0.149$.\\
Infine, sempre con le stesse feature, si è cambiato il modello in un \textbf{DecisionTreeRegressor}, ottenendo score legggermente più bassi ma sempre dell'ordine di $0.149$.\\
\\
Un miglioramento notevole, da $0.149$ a $0.14066$ si è avuto quando si sono introdotti i modelli \textbf{per-store}, ovvero assegnando (e addestrando) un modello diverso per ogni store, ognuno dedicato alle istanze relative a quello store. Non solo, questo miglioramento è anche dovuto al fatto di aver notevolmente diminuito il numero di feature utilizzate: mentre prima si usavano un po' tutti i campi del trainset, in questa fase si sono invece passati soltanto \textbf{DayOfWeek} e \textbf{Promo}. Per prove ed errori si è stabilito che le feature scartate aumentavano l'errore totale anziché diminuirlo. Da questo se ne è dedotto che tra i campi presenti nel trainset, gli unici veramente significativi sono quei due (escludendo \textit{Store} e \textit{Open}, che da qui in avanti non saranno più considerati vere e proprie feature).\\
\\
Dopodiché si sono cercati altri metodi, al di fuori dei campi del trainset, per migliorare ulteriormente il risultato.\\
\\
Un'idea è stata quella di usare come feature i campi \textit{StateHoliday} e \textit{SchoolHoliday} del giorno seguente. Intuitivamente, un negozio non venderà di più il giorno di Natale (in cui sarà probabilmente chiuso), ma il giorno prima! Per tentare di fare questo in modo efficiente, ovvero evitando di scorrere ogni volta il dataset, si era pensato di scrorrere una prima volta i dataset, andando a salvare in un dizionario le informarioni relative a ogni giornata. A questo proposito, venivano estratte le informazioni soltanto dalle istanze di ogni data relative allo store con id 1, dopotutto se un giorno è festa lo è indipendentemente dal negozio... no? Sbagliato! Quest'affermazione è falsa in quanto non considera la diversa localizzazione dei negozi (purtroppo anonima) e del fatto che in posti diversi potrebbero essere festeggiate feste diverse. Si osservi ad esempio la data 15 Agosto 2015 nel testset: per alcuni negozi è riportata come festa, mentre per altri come giorno normale! Facendo una piccola ricerca\footnote{I giorni festivi in Germania: \url{http://www.viaggio-in-germania.de/festivi.html}} si trova subito che in Germania (Rossman è una catena tedesca) il 15 Agosto viene festeggiata l'Assunzione di Maria Vergine, ma sono nelle regioni del Saarland e della Baviera! Quest'approccio è risultato quindi sbagliato e l'idea è stata accantonata per il momento, in attena di nuovi spunti per un'implementazione efficiente.\\
\\
Da un \textit{rmspe} di $0.14066$ si è riusciti a scendere all'attuale $0.13476$ aggiungendo un'ulteriore feature, relativa alla distanza dal negozio più vicino che rappresenta un qualche tipo di \textbf{concorrenza}. L'idea è semplice: per ogni store, estrai il campo \textit{CompetitionDistance} dal file \textit{store.csv} e usa la  distanza come feature solo nelle date successive a quella indicata. Se nessuna data è indicata, si assume che il negozio in questione era lì già da prima che venissero raccolti dati a riguardo, quindi si considera sempre presente dall'inizio del training. Se nessuna distanza è fornita, o per le date precedenti a quelle indicate, si assume che non ci sia uno store abbastanza vicino da essere considerato in concorrenza: in questo caso si assegna un valore infinito (\textit{sys.maxint}) alla distanza.\\
\\
Visti i buoni risultati ottenuti con \textit{CompetitionDistance} si è quindi provata una cosa simile per \textit{Promo2}. Leggendo la descrizione e andando a documentarsi nel forum della competizione si capisce che se un negozio lancia la Promo2, allora la lancia a partire da una certa settimana di un certo anno e ogni tre mesi la rinnova (\textit{PromoInterval}). Sul forum gli admin hanno spiegato che \textit{Promo2} rappresenta delle promozioni basate su coupon di sconto che valgono 3 mesi. Quindi, per gli store/date in cui Promo2 era attiva si è provato ad usare come feature la distanza (in giorni) tra la data attuale e l'inizio della mandata di coupon più recente. Tristemente l'errore è schizzato a $0.18$ circa, rendendo inutile questa feature.\\
\\
Al momento della stesura di questo elaborato, si stanno facendo prove per usare come feature il campo \textit{Open} ma del giorno successivo (un po' come tentato prima ma astraendo rispetto al concetto di festa e concentrandosi solo sul fatto che il giorno dopo il negozio sia chiuso o meno). Come prima si sta cercando un modo efficiente di estrarre quest'informazione senza dover riscorrere ogni volta il dataset (il costo passarebbe da lineare a quadratico!). Questa feature è al momento ``work in progress''.
